{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: x.permute(1, 2, 0).unsqueeze(1).repeat(1, 3, 1, 1),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.memmap('/scratch/arihanth.srikar/train_data.bin', dtype=np.uint8, mode='r').reshape(-1, 19, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = transforms.Compose([\n",
    "    transforms.Resize((224, 224), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: x*225\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset\")\n",
    "try:\n",
    "    df = pd.read_json('/home/ssd_scratch/users/arihanth.srikar/physionet.org/files/chest-imagenome/1.0.0/silver_dataset/mimic_coco_filtered.json')\n",
    "except:\n",
    "    df = pd.read_json('/scratch/arihanth.srikar/physionet.org/files/chest-imagenome/1.0.0/silver_dataset/mimic_coco_filtered.json')\n",
    "temp_df = pd.read_csv('data/mimic_cxr_jpg/mimic-cxr-2.0.0-final.csv')\n",
    "temp_df.rename(columns={'dicom_id': 'image_id'}, inplace=True)\n",
    "df = df.merge(temp_df, on='image_id', how='left')\n",
    "print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumpDataset(Dataset):\n",
    "    def __init__(self, df, transform=T):\n",
    "        self.df = df\n",
    "        self.img_loc_prefix = '/home/ssd_scratch/users/arihanth.srikar/physionet.org/files/mimic-cxr-jpg/2.0.0/files'\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_data = self.df.iloc[idx]\n",
    "        \n",
    "        try:\n",
    "            pid = str(int(sample_data['subject_id']))\n",
    "            sid = str(int(sample_data['study_id']))\n",
    "            image_file_location = f'{self.img_loc_prefix}/p{pid[:2]}/p{pid}/s{sid}/{sample_data[\"image_id\"]}.jpg'\n",
    "            img = Image.open(image_file_location)\n",
    "        except:\n",
    "            self.img_loc_prefix = '/scratch/arihanth.srikar/physionet.org/files/mimic-cxr-jpg/2.0.0/files'\n",
    "            return self.__getitem__(idx)\n",
    "        \n",
    "        sub_anatomies = []\n",
    "        sub_anatomy_labels = []\n",
    "        sub_anatomy_name = []\n",
    "        for annotation in sorted(sample_data['annotations'], key=lambda k: k['category_id']):\n",
    "            x, y, w, h = annotation['bbox']\n",
    "            sub_anatomy = img.crop((x, y, x+w, y+h))\n",
    "            sub_anatomy = self.transform(sub_anatomy).unsqueeze(0)\n",
    "            sub_anatomies.append(sub_anatomy)\n",
    "            sub_anatomy_name.append(annotation['id'].split('_')[-1])\n",
    "            sub_anatomy_labels.append(annotation['attributes'])\n",
    "            \n",
    "        img = self.transform(img)\n",
    "        images = torch.stack([img]+sub_anatomies)\n",
    "        sub_anatomy_labels = torch.tensor(sub_anatomy_labels).float()\n",
    "        global_label = (torch.sum(sub_anatomy_labels, dim=0) > 0).float()\n",
    "        nine_class_labels = torch.cat((global_label, sub_anatomy_labels), dim=0)\n",
    "\n",
    "        fourteen_class_labels = torch.from_numpy(sample_data[self.df.columns[-15:-1]].to_numpy().astype(np.float32))\n",
    "        \n",
    "        return {\n",
    "            'id': idx,\n",
    "            'images': images,\n",
    "            'y': nine_class_labels,\n",
    "            'anatomy_name': sub_anatomy_name,\n",
    "            'y_14': fourteen_class_labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dataset = DumpDataset(df, transform=T)\n",
    "dump_dataloader = DataLoader(dump_dataset, batch_size=16, shuffle=False, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_data = '/scratch/arihanth.srikar/data.bin'\n",
    "arr = np.memmap(save_file_data, dtype=np.uint8, mode='w+', shape=(len(dump_dataset), num_nodes+1, 224, 224))\n",
    "\n",
    "save_file_labels_9 = '/scratch/arihanth.srikar/nine_labels.bin'\n",
    "arr_labels_9 = np.memmap(save_file_labels_9, dtype=np.int8, mode='w+', shape=(len(dump_dataset), num_nodes+1, 9))\n",
    "\n",
    "save_file_labels_14 = '/scratch/arihanth.srikar/fourteen_labels.bin'\n",
    "arr_labels_14 = np.memmap(save_file_labels_14, dtype=np.int8, mode='w+', shape=(len(dump_dataset), 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, batch in enumerate(tqdm(dump_dataloader)):\n",
    "    for image, idx in zip(batch['images'], batch['id']):\n",
    "        arr[idx] = image.numpy().astype(np.uint8)\n",
    "        arr_labels_9[idx] = batch['y'].numpy().astype(np.int8)\n",
    "        arr_labels_14[idx] = batch['y_14'].numpy().astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
